import streamlit as st
import requests
from bs4 import BeautifulSoup
import time
import re


st.title("ğŸˆ My new app")
st.write(
    "Let's start building! For help and inspiration, head over to [docs.streamlit.io](https://docs.streamlit.io/)."
)



def scrape_naver_blog_content(blog_url):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        response = requests.get(blog_url, headers=headers)
        response.raise_for_status()  # ì‘ë‹µ ìƒíƒœ ì½”ë“œê°€ 200 OKê°€ ì•„ë‹ˆë©´ ì˜ˆì™¸ ë°œìƒ
        soup = BeautifulSoup(response.text, 'html.parser')

        # ë„¤ì´ë²„ ë¸”ë¡œê·¸ì˜ ë³¸ë¬¸ ë‚´ìš©ì€ ë‹¤ì–‘í•œ íƒœê·¸ì™€ í´ë˜ìŠ¤ì— ë‹´ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # ì•„ë˜ëŠ” ëª‡ ê°€ì§€ í”í•œ ê²½ìš°ë¥¼ ê°€ì •í•œ ì„ íƒìì´ë©°, ì‹¤ì œ ë¸”ë¡œê·¸ êµ¬ì¡°ì— ë”°ë¼ ìˆ˜ì •í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

        # 1. iframe ë‚´ë¶€ì˜ ë³¸ë¬¸ (ìµœê·¼ ë°©ì‹)
        main_frame = soup.find('iframe', id='mainFrame')
        if main_frame:
            iframe_url = main_frame['src']
            if not iframe_url.startswith('http'):
                base_url = blog_url.split('/')[0] + '//' + blog_url.split('/')[2]
                iframe_url = base_url + iframe_url
            iframe_response = requests.get(iframe_url, headers=headers)
            iframe_response.raise_for_status()
            iframe_soup = BeautifulSoup(iframe_response.text, 'html.parser')
            content_div = iframe_soup.find('div', class_='se-main-container') # ìŠ¤ë§ˆíŠ¸ ì—ë””í„°
            if not content_div:
                content_div = iframe_soup.find('div', id='postViewArea') # êµ¬ë²„ì „ ì—ë””í„°
            if content_div:
                return content_div.get_text(separator='\n', strip=True)

        # 2. iframe ì—†ì´ ì§ì ‘ ë³¸ë¬¸ (ê³¼ê±° ë°©ì‹ ë˜ëŠ” íŠ¹ì • ì„¤ì •)
        else:
            content_div = soup.find('div', class_='se-main-container') # ìŠ¤ë§ˆíŠ¸ ì—ë””í„°
            if not content_div:
                content_div = soup.find('div', id='postViewArea') # êµ¬ë²„ì „ ì—ë””í„°
            if content_div:
                return content_div.get_text(separator='\n', strip=True)

        return "ë³¸ë¬¸ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    except requests.exceptions.RequestException as e:
        print(f"ìš”ì²­ ì˜¤ë¥˜: {e}")
        return None
    except Exception as e:
        print(f"ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
        return None

def remove_blank_lines(text: str) -> str:
    # 1) Zeroâ€‘width space, BOM ê°™ì€ ë³´ì´ì§€ ì•ŠëŠ” ë¬¸ì ì œê±°
    for ch in ('\u200B', '\uFEFF'):
        text = text.replace(ch, '')

    # 2) ì¤„ êµ¬ë¶„ì„ ëª¨ë‘ '\n' ìœ¼ë¡œ í†µì¼
    text = text.replace('\r\n', '\n').replace('\r', '\n')

    # 3) ì™„ì „íˆ ê³µë°±ë§Œ ìˆëŠ” ì¤„(íƒ­, ìŠ¤í˜ì´ìŠ¤, NBSP ë“± í¬í•¨) ì œê±°
    #    (?m) ë©€í‹°ë¼ì¸ ëª¨ë“œ, ^â€¦$ ì— \s ë¥¼ ì¨ì„œ ìœ ë‹ˆì½”ë“œ ê³µë°± ì „ë¶€ ë§¤ì¹­
    cleaned = re.sub(r'(?m)^[\s\u00A0]*\n', '', text)

    # 4) ì•ë’¤ì— ë‚¨ì€ ë¹ˆ ì¤„/ê³µë°± ì˜ë¼ë‚´ê¸°
    return cleaned.strip()


if __name__ == "__main__":
    blog_url_to_scrape = "https://m.blog.naver.com/hkn238/223839853717" # ì—¬ê¸°ì— ìŠ¤í¬ë˜í•‘í•˜ë ¤ëŠ” ë„¤ì´ë²„ ë¸”ë¡œê·¸ URLì„ ë„£ì–´ì£¼ì„¸ìš”.
    content_1 = scrape_naver_blog_content(blog_url_to_scrape)
    content = remove_blank_lines(content_1)

    if content:
        st.write("ìŠ¤í¬ë˜í•‘ëœ ë³¸ë¬¸ ë‚´ìš©:\n")
        st.write(content)
    else:
        st.write("ë³¸ë¬¸ ìŠ¤í¬ë˜í•‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")