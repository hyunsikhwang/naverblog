import streamlit as st
import requests
from bs4 import BeautifulSoup
import re
import json
import base64
import os
from openai import OpenAI
import time


api_key = st.secrets["api_key"]

# Minimal + Modern CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
st.set_page_config(
    page_title="Naver Blog AI Scraper",
    page_icon="ğŸˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Premium Modern CSS using Google Fonts and Glassmorphism
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Outfit:wght@400;500;600;700&display=swap');

    :root {
        --primary: #4f46e5;
        --primary-hover: #4338ca;
        --bg-gradient: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%);
        --card-bg: rgba(255, 255, 255, 0.8);
        --text-main: #1e293b;
        --text-secondary: #64748b;
        --accent: #10b981;
    }

    .main {
        background: var(--bg-gradient);
        font-family: 'Inter', sans-serif;
    }

    /* Reduce top margin */
    .block-container {
        padding-top: 1rem !important;
        padding-bottom: 0rem !important;
    }

    /* Gradient Header */
    .header-container {
        padding: 1rem 0;
        text-align: center;
    }
    
    .gradient-text {
        background: linear-gradient(90deg, #4f46e5, #0ea5e9);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-family: 'Outfit', sans-serif;
        font-size: 3.5rem;
        font-weight: 800;
        margin-bottom: 0.5rem;
    }

    .subtitle {
        color: var(--text-secondary);
        font-size: 1.1rem;
        font-weight: 500;
    }

    /* Glassmorphism Card Style */
    .glass-card {
        background: var(--card-bg);
        backdrop-filter: blur(10px);
        -webkit-backdrop-filter: blur(10px);
        border-radius: 16px;
        border: 1px solid rgba(255, 255, 255, 0.3);
        padding: 1.5rem;
        box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.07);
        margin-bottom: 1.5rem;
        transition: transform 0.2s ease, box-shadow 0.2s ease;
    }

    .glass-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 12px 40px 0 rgba(31, 38, 135, 0.1);
    }

    /* Customizing Streamlit Components */
    .stSelectbox label, .stTextArea label {
        font-weight: 600 !important;
        color: var(--text-main) !important;
    }

    .stButton > button {
        background: linear-gradient(90deg, #4f46e5, #4338ca);
        color: white;
        border-radius: 12px;
        border: none;
        padding: 0.6rem 2rem;
        font-weight: 600;
        width: 100%;
        transition: all 0.3s ease;
    }

    .stButton > button:hover {
        background: linear-gradient(90deg, #4338ca, #3730a3);
        transform: scale(1.02);
    }

    /* Section Headers */
    .section-header {
        font-family: 'Outfit', sans-serif;
        font-size: 1.5rem;
        font-weight: 700;
        color: var(--text-main);
        margin-bottom: 1rem;
        display: flex;
        align-items: center;
        gap: 0.5rem;
    }

    .status-badge {
        background: #ecfdf5;
        color: #059669;
        padding: 0.25rem 0.75rem;
        border-radius: 9999px;
        font-size: 0.8rem;
        font-weight: 600;
    }
</style>

<div class="header-container">
    <h1 class="gradient-text">Naver Blog Scraper</h1>
    <p class="subtitle">AI-powered insights from Naver's most popular blogs</p>
</div>
""", unsafe_allow_html=True)


def fetch_post_list(category_no=0, item_count=24, page=1, user_id="gomting"):
    """
    ë„¤ì´ë²„ ëª¨ë°”ì¼ ë¸”ë¡œê·¸ APIì—ì„œ í¬ìŠ¤íŠ¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        category_no (int): ì¹´í…Œê³ ë¦¬ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 0)
        item_count (int): í•œ ë²ˆì— ê°€ì ¸ì˜¬ ì•„ì´í…œ ìˆ˜ (ê¸°ë³¸ê°’: 24)
        page (int): í˜ì´ì§€ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 1)
        user_id (str): ì‚¬ìš©ì ID (ì˜ˆ: "gomting")
    
    Returns:
        dict or None: JSON íŒŒì‹± ê²°ê³¼, ì‹¤íŒ¨ ì‹œ None
    """
    url = "https://m.blog.naver.com/api/blogs/ranto28/post-list"
    params = {
        "categoryNo": category_no,
        "itemCount": item_count,
        "page": page,
        "userId": user_id
    }
    # ì£¼ì–´ì§„ ëª¨ë“  í—¤ë”ë¥¼ ê·¸ëŒ€ë¡œ ë°˜ì˜
    headers = {
        "Host": "m.blog.naver.com",
        "Accept": "application/json, text/plain, */*",
        "Accept-Encoding": "gzip, deflate, br, zstd",
        "Accept-Language": "ko,en-US;q=0.9,en;q=0.8",
        "Referer": "https://m.blog.naver.com/ranto28?categoryNo=0&tab=1",
        "Sec-CH-UA": '"Google Chrome";v="135", "Not-A.Brand";v="8", "Chromium";v="135"',
        "Sec-CH-UA-Mobile": "?0",
        "Sec-CH-UA-Platform": '"macOS"',
        "Sec-Fetch-Dest": "empty",
        "Sec-Fetch-Mode": "cors",
        "Sec-Fetch-Site": "same-origin",
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36",
        "Priority": "u=1, i"
    }

    try:
        resp = requests.get(url, params=params, headers=headers, timeout=10)
        resp.raise_for_status()
        return resp.json()
    except requests.RequestException as e:
        print(f"ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    except ValueError:
        print("ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    return None

def print_blog_summary(response):
    links = {}
    """
    ë„¤ì´ë²„ ë¸”ë¡œê·¸ JSON ì‘ë‹µì—ì„œ ì£¼ìš” í•­ëª©ë§Œ ê°„ê²°í•˜ê²Œ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    # ìš”ì²­ ì„±ê³µ ì—¬ë¶€ í™•ì¸
    if not response.get('isSuccess', False):
        print("ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return

    result = response.get('result', {})
    items = result.get('items', [])

    if not items:
        print("í‘œì‹œí•  ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    for item in items:
        blog_id = item.get('domainIdOrBlogId')
        log_no = item.get('logNo')
        title = item.get('titleWithInspectMessage', '<ì œëª© ì—†ìŒ>')
        comments = item.get('commentCnt', 0)
        sympathies = item.get('sympathyCnt', 0)
        # ë³¸ë¬¸ì€ ì²« ë¬¸ì¥ë§Œ ì¶”ì¶œí•´ ê°„ëµí•˜ê²Œ ë³´ì—¬ì¤ë‹ˆë‹¤.
        brief = item.get('briefContents', '').split('ã€‚')[0]
        link = f"https://m.blog.naver.com/{blog_id}/{log_no}"

        # links.append(f"{link}")
        links[f"{title}"] = f"{link}"
        # print(f"ì œëª©       : {title}")
        # print(f"ë§í¬       : {link}")
        # print(f"ëŒ“ê¸€/ê³µê°  : {comments}ê°œ  /  {sympathies}ê°œ")
        # print(f"ìš”ì•½       : {brief}â€¦")
        # print("-" * 60)
    
    return links

def convert_to_mobile_url(pc_url: str) -> str:
    """
    PC ë²„ì „ ë„¤ì´ë²„ ë¸”ë¡œê·¸ URLì„ ëª¨ë°”ì¼ ë²„ì „ URLë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ì˜ˆ: https://blog.naver.com/ì•„ì´ë””/í¬ìŠ¤íŠ¸ë²ˆí˜¸ -> https://m.blog.naver.com/ì•„ì´ë””/í¬ìŠ¤íŠ¸ë²ˆí˜¸
    """
    if "blog.naver.com" not in pc_url:
        raise ValueError("ìœ íš¨í•œ ë„¤ì´ë²„ ë¸”ë¡œê·¸ URLì´ ì•„ë‹™ë‹ˆë‹¤.")
    # URLì´ ì´ë¯¸ ëª¨ë°”ì¼ ë²„ì „ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if "m.blog.naver.com" in pc_url:
        return pc_url

    # ê°„ë‹¨í•˜ê²Œ 'blog.naver.com'ì„ 'm.blog.naver.com'ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
    mobile_url = pc_url.replace("blog.naver.com", "m.blog.naver.com")
    return mobile_url

def scrape_naver_blog(pc_url: str) -> str:
    """
    ë„¤ì´ë²„ ë¸”ë¡œê·¸ PC ë²„ì „ URLì„ ë°›ì•„, ëª¨ë°”ì¼ í˜ì´ì§€ì—ì„œ ë³¸ë¬¸ HTMLì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    mobile_url = convert_to_mobile_url(pc_url)

    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/98.0.4758.102 Safari/537.36"
        )
    }
    response = requests.get(mobile_url, headers=headers)
    if not response.ok:
        raise ConnectionError(f"ëª¨ë°”ì¼ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")

    html_text = response.text
    soup = BeautifulSoup(html_text, "html.parser")

    # ì˜ˆì œ 1: ì¼ë°˜ì ì¸ ë³¸ë¬¸ ì»¨í…Œì´ë„ˆ divë¥¼ í™œìš©í•˜ëŠ” ê²½ìš°
    content_div = soup.find("div", {"class": "se-main-container"})
    if content_div:
        # return str(content_div)
        return content_div.get_text(separator='\n', strip=True)

    # ì˜ˆì œ 2: JSON ë°ì´í„°ê°€ í¬í•¨ëœ <script> íƒœê·¸ì—ì„œ ë³¸ë¬¸ ì¶”ì¶œ (ì˜ˆìƒ ë³€ìˆ˜ëª…ì´ __APOLLO_STATE__ ë“±)
    # ì•„ë˜ ì •ê·œì‹ì€ ì˜ˆì‹œì´ë©°, ì‹¤ì œ ë³€ìˆ˜ëª…ê³¼ êµ¬ì¡°ëŠ” HTML ì†ŒìŠ¤ í™•ì¸ í›„ ìˆ˜ì • í•„ìš”í•©ë‹ˆë‹¤.
    pattern = re.compile(r'window\.__APOLLO_STATE__\s*=\s*(\{.*?\});', re.DOTALL)
    match = pattern.search(html_text)
    if match:
        json_str = match.group(1).strip()
        try:
            data = json.loads(json_str)
            # ë°ì´í„° êµ¬ì¡°ì— ë”°ë¼ ìˆ˜ì • í•„ìš”: ì˜ˆì‹œë¡œ postContent í˜¹ì€ contentë¥¼ ì°¾ìŒ
            if "post" in data and "content" in data["post"]:
                return data["post"]["content"]
        except json.JSONDecodeError:
            pass  # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì•„ë˜ ë°©ë²• ì‚¬ìš©

    # ì˜ˆì œ 3: iframe êµ¬ì¡°ì¸ ê²½ìš°, iframeì˜ srcë¥¼ ì¶”ì¶œí•˜ì—¬ ì¶”ê°€ ìš”ì²­
    iframe = soup.find("iframe")
    if iframe and iframe.has_attr("src"):
        iframe_src = iframe["src"]
        iframe_response = requests.get(iframe_src, headers=headers)
        if iframe_response.ok:
            iframe_soup = BeautifulSoup(iframe_response.text, "html.parser")
            # iframe ë‚´ì— ë³¸ë¬¸ì´ ìˆëŠ”ì§€ í™•ì¸ (ì˜ˆ: div id="postViewArea")
            iframe_content = iframe_soup.find("div", {"id": "postViewArea"})
            if iframe_content:
                return str(iframe_content)

    raise ValueError("ë³¸ë¬¸ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. HTML êµ¬ì¡°ë¥¼ ì¬í™•ì¸í•´ ì£¼ì„¸ìš”.")

def insert_line_breaks(text):
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ ì•„ë˜ ì„¸ ê²½ìš°ì— ì¤„ë°”ê¿ˆì„ ì‚½ì…í•©ë‹ˆë‹¤:
    1) ë¬¸ì¥ì´ ë§ˆì¹¨í‘œë¡œ ëë‚œ ì§í›„
    2) ì¼ë ¨ë²ˆí˜¸(ì˜ˆ: '1.')ê°€ ë‚˜ì˜¤ê¸° ë°”ë¡œ ì•
    3) 'í•œì¤„ì½”ë©˜íŠ¸' ë˜ëŠ” 'í•œì¤„ ì½”ë©˜íŠ¸'ê°€ ë‚˜ì˜¤ê¸° ë°”ë¡œ ì§ì „
    """
    # 1) ë¬¸ì¥ì´ ë§ˆì¹¨í‘œë¡œ ëë‚œ ì§í›„: '...' ë’¤ì— \n ì¶”ê°€
    #    (?<!\n) ìœ¼ë¡œ ì´ë¯¸ ì¤„ë°”ê¿ˆì´ ì—†ëŠ” ê²½ìš°ë§Œ ì²˜ë¦¬
    text = re.sub(r'(?<!\n)\.(?=\s|$)', r'.\n', text)

    # 2) ì¼ë ¨ë²ˆí˜¸ ì•: 'ìˆ«ì+.' ì•ì— \n ì¶”ê°€
    text = re.sub(r'(?<!\n)(?=(\d+\.))', r'\n', text)

    # 3) 'í•œì¤„ì½”ë©˜íŠ¸' ë˜ëŠ” 'í•œì¤„ ì½”ë©˜íŠ¸' ë°”ë¡œ ì§ì „: ì•ì— \n ì¶”ê°€
    text = re.sub(r'(?<!\n)(?=(í•œì¤„\s*ì½”ë©˜íŠ¸))', r'\n', text)

    return text

def generate(api_key, content_html, is_ranto28=True):

    if is_ranto28:
        prompt_text = f"""ë‹¤ìŒ ì›ë¬¸ì—ì„œ í•œì¤„ ì½”ë©˜íŠ¸ë§Œ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´ì„œ ì¶œë ¥í•´ì£¼ì„¸ìš”.
í•œì¤„ ì½”ë©˜íŠ¸: {{í•œì¤„ ì½”ë©˜íŠ¸}}
ì›ë¬¸: {content_html}"""
    else:
        # For other blogs, provide Implications and 5-10 bullet points
        prompt_text = f"""ë‹¤ìŒ ì›ë¬¸ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ 'ì‹œì‚¬ì 'ê³¼ í•¨ê»˜ 5ê°œì—ì„œ 10ê°œ ì‚¬ì´ì˜ í•µì‹¬ ë‚´ìš©ì„ ë¶ˆë › í¬ì¸íŠ¸(bullet points)ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
í…ìŠ¤íŠ¸ì˜ ë¶„ëŸ‰ì— ë”°ë¼ ë¶ˆë › í¬ì¸íŠ¸ ê°œìˆ˜ë¥¼ 5ê°œì—ì„œ 10ê°œ ì‚¬ì´ë¡œ ì ì ˆíˆ ì¡°ì ˆí•´ ì£¼ì„¸ìš”.

í˜•ì‹:
[ì‹œì‚¬ì ]
(ì—¬ê¸°ì— ì‹œì‚¬ì  ë‚´ìš© ì‘ì„±)

[í•µì‹¬ ìš”ì•½]
- (í•µì‹¬ ë‚´ìš© 1)
- (í•µì‹¬ ë‚´ìš© 2)
...

ì›ë¬¸: {content_html}"""

    client = OpenAI(
        api_key=api_key,
        base_url="https://openrouter.ai/api/v1",
    )

    model = "openai/gpt-oss-120b:free"

    stream = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "user", "content": prompt_text},
        ],
        stream=True,
    )

    for chunk in stream:
        if chunk.choices[0].delta.content is not None:
            yield chunk.choices[0].delta.content
        time.sleep(0.01)

def get_full_response(api_key, content_html, is_ranto28=True):
    """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì™„ì „í•œ í…ìŠ¤íŠ¸ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    full_response = ""
    for chunk in generate(api_key, content_html, is_ranto28):
        full_response += chunk
    return full_response

def extract_comment(full_response):
    """ì‘ë‹µì—ì„œ í•œì¤„ ì½”ë©˜íŠ¸ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    comment_match = re.search(r'í•œì¤„ ì½”ë©˜íŠ¸:\s*(.*?)(?=\nì›ë¬¸:|$)', full_response, re.DOTALL)
    comment = comment_match.group(1).strip() if comment_match else "í•œì¤„ ì½”ë©˜íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    return comment

def remove_blank_lines(text: str) -> str:
    # 1) Zeroâ€‘width space, BOM ê°™ì€ ë³´ì´ì§€ ì•ŠëŠ” ë¬¸ì ì œê±°
    for ch in ('\u200B', '\uFEFF'):
        text = text.replace(ch, '')

    # 2) ì¤„ êµ¬ë¶„ì„ ëª¨ë‘ '\n' ìœ¼ë¡œ í†µì¼
    text = text.replace('\r\n', '\n').replace('\r', '\n')

    # 3) ì™„ì „íˆ ê³µë°±ë§Œ ìˆëŠ” ì¤„(íƒ­, ìŠ¤í˜ì´ìŠ¤, NBSP ë“± í¬í•¨) ì œê±°
    #    (?m) ë©€í‹°ë¼ì¸ ëª¨ë“œ, ^â€¦$ ì— \s ë¥¼ ì¨ì„œ ìœ ë‹ˆì½”ë“œ ê³µë°± ì „ë¶€ ë§¤ì¹­
    cleaned = re.sub(r'(?m)^[\s\u00A0]*\n', '', text)

    # 4) ì•ë’¤ì— ë‚¨ì€ ë¹ˆ ì¤„/ê³µë°± ì˜ë¼ë‚´ê¸°
    return cleaned.strip()

if __name__ == "__main__":
    # Settings in Sidebar
    with st.sidebar:
        st.markdown('<div class="section-header">âš™ï¸ Settings</div>', unsafe_allow_html=True)
        
        custom_url = st.text_input("Custom Naver Blog URL (Optional):", placeholder="https://blog.naver.com/...")
        
        response = fetch_post_list()
        if response:
            links = print_blog_summary(response)
            if links:
                titles = list(links.keys())
                selected_title = st.selectbox("Or Select from Recent Posts:", titles)
                
                if not custom_url:
                    st.info(f"ğŸ”— [Open Original Post]({links[selected_title]})")
                else:
                    st.info(f"ğŸ”— [Open Custom Post]({custom_url})")
            else:
                st.error("Could not fetch post list.")
                st.stop()
        else:
            st.error("Failed to connect to Naver API.")
            st.stop()

    # Main Content Area
    col1, col2 = st.columns([1, 1], gap="large")

    try:
        with st.spinner("âœ¨ AI is analyzing the post..."):
            if custom_url:
                post_url = custom_url
                display_title = "Custom URL Post"
            else:
                post_url = links[selected_title]
                display_title = selected_title
                
            is_ranto28 = "ranto28" in post_url
            
            content_text = scrape_naver_blog(post_url)
            content_text = remove_blank_lines(content_text)
            
            # AI Inference
            full_response = get_full_response(api_key, content_text, is_ranto28=is_ranto28)
            
            if is_ranto28:
                summary_content = extract_comment(full_response)
            else:
                summary_content = full_response

        with col1:
            st.markdown('<div class="section-header">ğŸ“ AI Summary <span class="status-badge">Powered by GPT-4</span></div>', unsafe_allow_html=True)
            st.markdown(f"""
            <div class="glass-card">
                <div style="font-size: 1.1rem; line-height: 1.6; color: #1e293b; font-weight: 500; white-space: pre-wrap;">
                    {summary_content}
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown('<div class="section-header">ğŸ“¥ Export</div>', unsafe_allow_html=True)
            st.download_button(
                label="Download Original Content (.txt)",
                data=content_text,
                file_name=f"{display_title}.txt",
                mime="text/plain",
                use_container_width=True
            )

        with col2:
            st.markdown('<div class="section-header">ğŸ“„ Original Content</div>', unsafe_allow_html=True)
            
            # Clipboard Copy Button implementation
            import json
            
            # Use columns for labels and copy button
            c1, c2 = st.columns([3, 1])
            with c2:
                # Custom JS for clipboard copy
                safe_text = json.dumps(content_text)
                copy_button_html = f"""
                <button onclick='navigator.clipboard.writeText({safe_text})' style="
                    background-color: #4f46e5;
                    color: white;
                    border: none;
                    padding: 8px 16px;
                    border-radius: 8px;
                    cursor: pointer;
                    font-family: 'Inter', sans-serif;
                    font-size: 0.8rem;
                    float: right;
                ">ğŸ“‹ Copy Content</button>
                """
                st.components.v1.html(f"""
                <style>
                    button:hover {{
                        background-color: #4338ca !important;
                    }}
                </style>
                {copy_button_html}
                """, height=50)

            st.markdown(f"""
            <div class="glass-card" style="height: 500px; overflow-y: auto;">
                <pre style="white-space: pre-wrap; font-family: 'Inter', sans-serif; font-size: 0.9rem; color: #475569;">
{content_text}
                </pre>
            </div>
            """, unsafe_allow_html=True)

    except Exception as e:
        st.error(f"An error occurred: {e}")
        st.exception(e)
